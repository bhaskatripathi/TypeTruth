import requests
import numpy as np
import pandas as pd
import re

class ContentGeneratorChecker:
    def __init__(self, token):
        self.header = {
            'Accept': '*/*',
            'Accept-Language': 'en-US,en;q=0.9,hi;q=0.8',
            'Authorization': token,
            'Connection': 'keep-alive',
            'Content-Type': 'application/json',
            'Origin': 'https://platform.openai.com',
            'Referer': 'https://platform.openai.com/',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-site',
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',
            'sec-ch-ua': '"Not_A Brand";v="99", "Google Chrome";v="109", "Chromium";v="109"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"macOS"',
        }
        self.possible_classes = [
            'Very unlikely to be AI-generated',
            'Unlikely to be AI-generated',
            'Cannot determine if AI-written or human-written',
            'Possibly AI-generated',
            'Likely AI-generated',
        ]
        self.class_max = [10, 45, 90, 98, 99]

    def detect(self, text, all_probs=False):
        data = {
            'prompt': text + "Â».\n",
            'max_tokens': 1,
            'temperature': 1,
            'top_p': 1,
            'n': 1,
            'logprobs': 5,
            'stop': '\n',
            'stream': False,
            'model': 'model-detect-v2',
        }
        try:
            response = requests.post('https://api.openai.com/v1/completions', headers=self.header, json=data)
            response.raise_for_status()
        except requests.exceptions.HTTPError as err:
            if response.status_code == 401:
                return "Error: Invalid bearer token"
            else:
                return f"HTTP error occurred: {err}"

        if response.status_code == 200:
            choices = response.json()['choices'][0]
            logprobs = choices['logprobs']['top_logprobs'][0]
            probs = {key: round(100 * np.e ** value, 2) for key, value in logprobs.items()}
            key_prob = probs['"']
            if self.class_max[0] < key_prob < self.class_max[len(self.class_max) - 1]:
                val = max(i for i in self.class_max if i < key_prob)
                class_label = self.possible_classes[self.class_max.index(val)]
            elif self.class_max[0] > key_prob:
                class_label = self.possible_classes[0]
            else:
                class_label = self.possible_classes[len(self.possible_classes) - 1]
            top_prob = {'Class': class_label, 'AI-Generated Probability': key_prob}
            if all_probs:
                return probs, top_prob
            return top_prob
        return "Check prompt, Length of sentence it should be more than 1,000 characters"

class AIDetector:
    def __init__(self, token_path='openai_bearer.txt'):
        with open(token_path) as file:
            self.bearer_token = file.readline().strip()
        self.od = ContentGeneratorChecker(self.bearer_token)

    def human_or_ai(self, score):
        if score >= 90:
            human_prob = 100 - score
            return score, human_prob, f"{score:.2f}% of the Text generated by AI."
        elif score >= 70:
            human_prob = 100 - score
            return score, human_prob, f"{score:.2f}% of the Text generated by AI."
        elif 60 > score >= 50:
            human_prob = 100 - score
            return score, human_prob, "AI text written by Human or Human written text improved by AI."
        elif score >= 30:
            human_prob = 100 - score
            return score, human_prob, f"{human_prob:.2f}% Text written by human."
        else:
            human_prob = 100 - score
            return score, human_prob, f"{human_prob:.2f}% Text written by human."

    def detect(self, text, split_type='sentence'):
        if split_type == 'sentence':
            chunks = text.split(". ")
        elif split_type == 'paragraph':
            chunks = re.split('\n+', text)
        else:
            return "Invalid split_type. Choose 'sentence' or 'paragraph'."
            
        chunk_list = []
        for chunk in chunks:
            ai_response = self.od.detect(chunk)
            if isinstance(ai_response, str):
                return ai_response
            else:
                ai_score, human_score, human_or_ai_confidence = self.human_or_ai(ai_response['AI-Generated Probability'])
                chunk_list.append([chunk, ai_score, human_score, human_or_ai_confidence])

        df = pd.DataFrame(chunk_list, columns=['Chunk', 'AI Score', 'Human Score', 'Confidence'])
        return df
